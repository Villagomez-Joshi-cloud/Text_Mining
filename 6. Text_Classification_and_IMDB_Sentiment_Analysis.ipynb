{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links shared:\n",
    "\n",
    "* http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/\n",
    "* https://streamhacker.com/2010/05/10/text-classification-sentiment-analysis-naive-bayes-classifier/\n",
    "* https://www.w3schools.com/python/default.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1ufkmzZEa4KT",
    "outputId": "065d0cfc-d07d-4ddb-aea6-e6ff414c3ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#Tokenization of text\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "#remove stop-words\n",
    "from nltk.corpus import stopwords # library \n",
    "nltk.download('stopwords')\n",
    "all_stopwords = set(stopwords.words('english')) # set the language \n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "HSfNL1sUhfmx",
    "outputId": "0764dc6c-811d-4acf-c606-fe1575b2e1c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading review data with panda frames \n",
    "reviews_data=pd.read_csv('IMDB Dataset.csv')\n",
    "reviews_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2BLnmj7Pin5k"
   },
   "source": [
    "We have 50K reviews of which 49582 reviews are unique and have two types of sentiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "arFkf23QhtSt",
    "outputId": "4dc0907d-e09f-4d73-c16e-418fb7b265ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentiment counts\n",
    "reviews_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vcd5fWyLi0zc"
   },
   "source": [
    "The sentiments are either 'positive' or 'negative' and are evenly distributed. Lets preprocess the text using the simple tokenizer we built in last class. We call it preprocess_text now.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TU4XknHUgoKC",
    "outputId": "b94567d8-f5c0-4255-edfe-e5dc9828c469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hated film disaster poor direction bad acting\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text: str) -> List[str]:\n",
    "    # Looking at the text we see that <br></br> which is HTML tag for line break can be a good splitter\n",
    "    # A sentence (atleast well structured) often has a full spot at the end. We use these two for word breaks\n",
    "    pattern1 = re.compile(\"<br /><br />|\\.\")\n",
    "    lines = re.split(pattern1, text)\n",
    "    # you can break a sentence into words using whitespace based split\n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        tokens += line.split(\" \")\n",
    "\n",
    "    # lowercase and remove any non-alphanumeric characters from tokens for normalize\n",
    "    normalized_tokens = [re.sub(r\"\\W+\", \"\", token.lower()) for token in tokens]\n",
    "    return  \" \".join([\n",
    "            token\n",
    "            for token in normalized_tokens\n",
    "            if token and token not in all_stopwords and len(tokens) > 1 \n",
    "        ])\n",
    "    \n",
    "\n",
    "  \n",
    "custom_review = \"I hated the film. It was a disaster. Poor direction, bad acting.\"\n",
    "custom_review_tokens = preprocess_text(custom_review)\n",
    "print(custom_review_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f4sY8_cdlgtp"
   },
   "outputs": [],
   "source": [
    "#apply preprocessing to review data\n",
    "reviews_data['review'] = reviews_data['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "BU6_f3p6a-9A",
    "outputId": "ccd106c8-9cc1-4227-983a-b78eb80fc135"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,) (40000,)\n",
      "(5000,) (5000,)\n",
      "(5000,) (5000,)\n"
     ]
    }
   ],
   "source": [
    "#split the dataset  \n",
    "#train dataset\n",
    "train_reviews=reviews_data.review[:40000]\n",
    "train_sentiments=reviews_data.sentiment[:40000]\n",
    "#test dataset\n",
    "test_reviews=reviews_data.review[40000:45000]\n",
    "test_sentiments=reviews_data.sentiment[40000:45000]\n",
    "#validation (blind) dataset\n",
    "blind_reviews=reviews_data.review[45000:]\n",
    "blind_sentiments=reviews_data.sentiment[45000:]\n",
    "print(train_reviews.shape,train_sentiments.shape)\n",
    "print(test_reviews.shape,test_sentiments.shape)\n",
    "print(blind_reviews.shape,blind_sentiments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "vvDK_SPafGga",
    "outputId": "53adc0f4-2611-4ff0-b5e5-e9a93f43bda7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_cv_train: (40000, 5144)\n",
      "BOW_cv_test: (5000, 5144)\n",
      "BOW_cv_blind: (5000, 5144)\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer implements both tokenization and occurrence counting in a single class. Read more here https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# You can also reuse the from scratch code we learnt in previous class\n",
    "# TfidfVectorizer Convert a collection of raw documents to a matrix of TF-IDF features. Equivalent to CountVectorizer followed by TfidfTransformer.\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#Count vectorizer with \n",
    "lower_count_thr = 100 # rare words/tokens\n",
    "upper_count_thr = 5000 # frequent/common tokens\n",
    "\n",
    "tv=TfidfVectorizer(min_df=lower_count_thr,max_df=upper_count_thr,binary=False,ngram_range=(1,1))\n",
    "#transformed train reviews\n",
    "tv_train_reviews=tv.fit_transform(train_reviews)\n",
    "#transformed test reviews\n",
    "tv_test_reviews=tv.transform(test_reviews)\n",
    "\n",
    "#transformed validation reviews\n",
    "tv_blind_reviews=tv.transform(blind_reviews)\n",
    "\n",
    "print('BOW_cv_train:',tv_train_reviews.shape)\n",
    "print('BOW_cv_test:',tv_test_reviews.shape)\n",
    "print('BOW_cv_blind:',tv_blind_reviews.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O4EA4joVsQKa",
    "outputId": "42f0fe58-28e8-427d-a815-f70afc1a34df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Now generate binary (true, false) labels from sentiment values. positive maps to 1, negative maps to 0\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb=LabelBinarizer()\n",
    "#transformed sentiment data\n",
    "sentiment_data=lb.fit_transform(reviews_data['sentiment'])\n",
    "print(sentiment_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "xmTB3H9GqrYM",
    "outputId": "ea1257e9-b28b-4381-ee2b-487e2bcbba98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 1)\n",
      "(5000, 1)\n",
      "(5000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Spliting the sentiment data\n",
    "train_sentiments=sentiment_data[:40000]\n",
    "test_sentiments=sentiment_data[40000:45000]\n",
    "blind_sentiments=sentiment_data[45000:]\n",
    "print(train_sentiments.shape)\n",
    "print(test_sentiments.shape)\n",
    "print(blind_sentiments.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jNssxD-etGzz"
   },
   "source": [
    "Now that we have both vectorized data and binary labels we are ready to train classifier model. The objective of binary classifier is to predict 0/1 label based on features. We use many types of classifier for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "Ha0tPAputGPn",
    "outputId": "faf5a761-51de-4df3-b6aa-4bf0f6bd5537"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "#training Logistic model\n",
    "lr=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
    "#Fitting the model for tfidf features\n",
    "lr_tfidf=lr.fit(tv_train_reviews,train_sentiments)\n",
    "print(lr_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JypmAEoltvmy"
   },
   "source": [
    "Now we use the trained model to predict sentiment label on both test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xvZAWAMztzDm",
    "outputId": "0110a448-04d9-4ac4-ebd7-7ee4e834725a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "##Predicting the model for test set\n",
    "lr_tfidf_predict_test=lr.predict(tv_test_reviews)\n",
    "print(lr_tfidf_predict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZSnr_d0uZUT"
   },
   "source": [
    "Next we compute accuracy of the prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "6jKCC4rruZiE",
    "outputId": "f2e05c74-865c-49f7-c8a3-55d693d27b05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_tfidf_score : 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.89      0.87      0.88      2463\n",
      "    Negative       0.88      0.89      0.88      2537\n",
      "\n",
      "    accuracy                           0.88      5000\n",
      "   macro avg       0.88      0.88      0.88      5000\n",
      "weighted avg       0.88      0.88      0.88      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "lr_tfidf_score=accuracy_score(test_sentiments,lr_tfidf_predict_test)\n",
    "print(\"lr_tfidf_score :\",lr_tfidf_score)\n",
    "\n",
    "#Classification report for tfidf features\n",
    "lr_tfidf_report_test=classification_report(test_sentiments,lr_tfidf_predict_test,target_names=['Positive','Negative'])\n",
    "print(lr_tfidf_report_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Text Classification and IMDB_Sentiment_Analysis",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
